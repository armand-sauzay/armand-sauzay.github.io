<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9q9Wr6rz5Li6IZcgLD7_Ig.jpeg"/><link rel="preload" as="image" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BG6W1B8OW6gUVHPbBXIvIA.png"/><link rel="preload" as="image" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9M6mMjsGH_nj0BG_7uJpCg.png"/><link rel="preload" as="image" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGEnQK781FHnjEwexOklbg.png"/><link rel="preload" as="image" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPp8lnK6n2peGk1wbBb8Og.png"/><link rel="preload" as="image" href="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zI3DWLj7E71y4jyVHHJx9g.png"/><link rel="stylesheet" href="/_next/static/css/27c4eb1be0a8ef66.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-87b4446f5aacfc58.js"/><script src="/_next/static/chunks/4bd1b696-d0010192273b2f08.js" async=""></script><script src="/_next/static/chunks/517-34c25e9c69b3332f.js" async=""></script><script src="/_next/static/chunks/main-app-a6b2e7fa0ef815fd.js" async=""></script><script src="/_next/static/chunks/173-24113e259ce525da.js" async=""></script><script src="/_next/static/chunks/app/articles/page-9a53c5301fbc680c.js" async=""></script><script src="/_next/static/chunks/313-6cc61c2fd8ca5084.js" async=""></script><script src="/_next/static/chunks/app/articles/%5Bslug%5D/page-444914622aa9eeee.js" async=""></script><meta name="next-size-adjust" content=""/><title>Armand Sauzay</title><meta name="description" content="Personal website of Armand Sauzay"/><link rel="icon" href="/favicon.ico"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_d65c78 min-h-screen flex flex-col"><div><nav class="p-6"><div class="max-w-4xl mx-auto flex justify-between items-center"><a class="text-[#005530] font-semibold text-xl" href="/">armandsauzay</a><div class="flex gap-6"><a class="text-gray-600 hover:text-[#24512B] transition-colors flex items-center gap-2 cursor-pointer" href="/articles"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-book-open h-5 w-5"><path d="M12 7v14"></path><path d="M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z"></path></svg><span>Articles</span></a><a class="text-gray-600 hover:text-[#24512B] transition-colors flex items-center gap-2 cursor-pointer" href="/projects"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-code-xml h-5 w-5"><path d="m18 16 4-4-4-4"></path><path d="m6 8-4 4 4 4"></path><path d="m14.5 4-5 16"></path></svg><span>Projects</span></a><a class="text-gray-600 hover:text-[#24512B] transition-colors flex items-center gap-2 cursor-pointer" href="/creative-lab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-brain h-5 w-5"><path d="M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z"></path><path d="M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z"></path><path d="M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4"></path><path d="M17.599 6.5a3 3 0 0 0 .399-1.375"></path><path d="M6.003 5.125A3 3 0 0 0 6.401 6.5"></path><path d="M3.477 10.896a4 4 0 0 1 .585-.396"></path><path d="M19.938 10.5a4 4 0 0 1 .585.396"></path><path d="M6 18a4 4 0 0 1-1.967-.516"></path><path d="M19.967 17.484A4 4 0 0 1 18 18"></path></svg><span>Creative Lab</span></a></div></div></nav><div class="max-w-4xl mx-auto border-b border-gray-200"></div></div><main class="flex-1 flex flex-col items-center justify-center"><div class="min-h-screen flex flex-col"><main class="flex-1 max-w-4xl mx-auto px-4 py-16"><article class="prose prose-neutral max-w-2xl mx-auto p-6 prose-pre:border-0"><p>This article lives on:</p>
<ul>
<li><a href="https://medium.com/@armand-sauzay/shap-values-machine-learning-interpretability-and-feature-selection-made-easy-feb8765f815b">Meduim</a></li>
<li><a href="https://dev.to/armandsauzay/shap-values-machine-learning-interpretability-and-feature-selection-made-easy-396k">Dev.to</a></li>
</ul>
<h1 id="shap-values-machine-learning-interpretability-and-feature-selection-madeeasy">SHAP values: Machine Learning interpretability and feature selection made easy.</h1>
<p>Machine learning interpretability with hands on code with SHAP.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9q9Wr6rz5Li6IZcgLD7_Ig.jpeg" alt="Photo by Edu Grande on Unsplash" node="[object Object]"/></p>
<p align="center">Photo by Edu Grande on Unsplash</p>
<p>Machine Learning interpretability is becoming increasingly important, especially as ML algorithms are getting more complex.</p>
<p>How good is your Machine Learning algorithm if it cant be explained? Less performant but explainable models (like linear regression) are sometimes preferred over more performant but black box models (like XGBoost or Neural Networks). This is why research around machine learning explainability (aka eXplainable AI or XAI) has recently been a growing field with amazing projects like SHAP emerging.</p>
<blockquote>
<p>Would you feel confident using a machine learning model if you can&#x27;t explain what it does?</p>
</blockquote>
<p>This is where SHAP can be of great help: it can explain <strong>any ML model</strong> by giving the influence of each of the features on the target. But this is not all that SHAP can do.</p>
<p>Build a simple model (sklearn/xgboost/keras) and use SHAP: you now have a feature selection process by looking at features which have the biggest impact on the prediction.
But how does SHAP work under the hood? And how can you start using it?</p>
<p>In this article we&#x27;ll first get our hands on some python code to see how you can start using SHAP and how it can help you both for explainability and feature selection.</p>
<p>Then, for those of you who want to get into the details of SHAP, we&#x27;ll go through the theory behind popular XAI tools like SHAP and LIME.</p>
<hr/>
<p>All the code for this tutorial can be found on Kaggle <a href="https://www.kaggle.com/code/armandsauzay/shap-interpret-any-ml-model-feature-selection?scriptVersionId=99746743">here</a>. Feel free to run the notebook yourself or create a copy!</p>
<hr/>
<h2 id="1-how-can-you-start-usingshap">1. How can you start using SHAP?</h2>
<p>Here, we&#x27;ll go through a simple example with Shap values using the competition Kaggle competition &quot;House Prices - Advanced Regression Techniques&quot; to illustrate SHAP. If you are interested or you have never been on Kaggle before, feel free to read more about the data and the competition itself here.</p>
<p>The process to use shap is quite straightforward: we need to build a model and then use the shap library to explain it.
<img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BG6W1B8OW6gUVHPbBXIvIA.png" alt="Explanation of how to use SHAP in your Machine Learning Project" node="[object Object]"/></p>
<p>understand the output of your modelHere, our machine learning model tries to predict the house prices from the data that is given (number of square feet, quality, number of floors etc).</p>
<p>The usual workflow in terms of code looks like this:</p>
<ol>
<li>Create an estimator. For instance GradientBoostingRegressor from sklearn.ensemble:
<pre><div style="position:relative"><button aria-label="Copy code" style="position:absolute;top:8px;right:8px;z-index:10;background:none;border:none;padding:0;cursor:pointer;opacity:0.7;transition:opacity 0.2s"><svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>estimator </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> GradientBoostingRegressor</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>random_state </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> random_state</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre></div></pre>
</li>
<li>Train your estimator:
<pre><div style="position:relative"><button aria-label="Copy code" style="position:absolute;top:8px;right:8px;z-index:10;background:none;border:none;padding:0;cursor:pointer;opacity:0.7;transition:opacity 0.2s"><svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>estimator</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>fit</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>X_train</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> y_train</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre></div></pre>
</li>
<li>use shap library to calculate the SHAP values. For instance, using the following code:
<pre><div style="position:relative"><button aria-label="Copy code" style="position:absolute;top:8px;right:8px;z-index:10;background:none;border:none;padding:0;cursor:pointer;opacity:0.7;transition:opacity 0.2s"><svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>explainer </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> shap</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>Explainer</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>estimator</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>predict</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> X100</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>shap_values </span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span> explainer</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>X100</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre></div></pre>
</li>
<li>See what is the impact of each feature using shap.summary_plot:
<pre><div style="position:relative"><button aria-label="Copy code" style="position:absolute;top:8px;right:8px;z-index:10;background:none;border:none;padding:0;cursor:pointer;opacity:0.7;transition:opacity 0.2s"><svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>shap</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>summary_plot</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>shap_values</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> max_display</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">15</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> show</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">False</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span><span>
</span><span>shap</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>summary_plot</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>shap_values</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> max_display</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">15</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> show</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">False</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre></div></pre>
</li>
</ol>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9M6mMjsGH_nj0BG_7uJpCg.png" alt="Summary plot of feature importance" node="[object Object]"/></p>
<p>For instance, you can see here that OverallQual is the feature that has the most impact on the model output. High values (colored in red on the graph above) of OverallQual can increase a property&#x27;s price by ~60,000 and low values can decrease a price by ~20,000. Interesting to know if you&#x27;re in real estate, isn&#x27;t it?</p>
<p>But this is not all of what SHAP can do! SHAP can also explain a single prediction.</p>
<p>For example, using shap.plots.waterfall for a single element in the dataset, you can have the following:</p>
<pre><div style="position:relative"><button aria-label="Copy code" style="position:absolute;top:8px;right:8px;z-index:10;background:none;border:none;padding:0;cursor:pointer;opacity:0.7;transition:opacity 0.2s"><svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>shap</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>plots</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>waterfall</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>shap_values</span><span class="token" style="color:hsl(230, 8%, 24%)">[</span><span>sample_index</span><span class="token" style="color:hsl(230, 8%, 24%)">]</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> max_display</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">14</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre></div></pre>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGEnQK781FHnjEwexOklbg.png" alt="Waterfall plot of feature importance for a single example" node="[object Object]"/></p>
<p>For this specific example, the predicted price was 166k (vs 174k on average). And we can understand why the algorithm predicted such: for instance OverallQual which is high (7) drives the value up but YearBuilt (1925) drives the value down.</p>
<p>You can now understand the dynamics behind your model, both overall and on specific datapoints. With SHAP, you can more easily see if something is wrong (or does not make sense for your sharpened data science mind) so you can correct it! This is what observability is about.</p>
<p>And since SHAP allows you to understand the feature importance of your model, you can also use this for feature selection. For instance</p>
<pre><div style="position:relative"><button aria-label="Copy code" style="position:absolute;top:8px;right:8px;z-index:10;background:none;border:none;padding:0;cursor:pointer;opacity:0.7;transition:opacity 0.2s"><svg width="20" height="20" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24"><rect x="9" y="9" width="13" height="13" rx="2" ry="2" stroke="currentColor"></rect><path d="M5 15H4a2 2 0 0 1-2-2V4a2 2 0 0 1 2-2h9a2 2 0 0 1 2 2v1"></path></svg></button><pre style="background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;padding:1em;margin:0.5em 0;overflow:auto;border-radius:0.3em"><code class="language-python" style="white-space:pre;background:hsl(230, 1%, 98%);color:hsl(230, 8%, 24%);font-family:&quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace;direction:ltr;text-align:left;word-spacing:normal;word-break:normal;line-height:1.5;-moz-tab-size:2;-o-tab-size:2;tab-size:2;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none"><span>shap</span><span class="token" style="color:hsl(230, 8%, 24%)">.</span><span>summary_plot</span><span class="token" style="color:hsl(230, 8%, 24%)">(</span><span>shap_values</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> max_display</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">15</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> show</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(35, 99%, 36%)">False</span><span class="token" style="color:hsl(230, 8%, 24%)">,</span><span> plot_type</span><span class="token" style="color:hsl(221, 87%, 60%)">=</span><span class="token" style="color:hsl(119, 34%, 47%)">&#x27;bar&#x27;</span><span class="token" style="color:hsl(230, 8%, 24%)">)</span></code></pre></div></pre>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPp8lnK6n2peGk1wbBb8Og.png" alt="Barplot of feature importance" node="[object Object]"/></p>
<p>Then you can see which features do not have a lot of impact on the output of the model. The features usually are noise for your machine learning model and do not bring a lot of predictive value. So removing them from your training set will generally improve the performance, and allow you to tune correctly the hyper parameters without overfitting on noisy data.
<img src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zI3DWLj7E71y4jyVHHJx9g.png" alt="Worfklow for feature selection in your machine learning project" node="[object Object]"/></p>
<p align="center"> How SHAP can be used for feature selection </p>
<h2 id="2-quick-overview-how-does-shap-work-under-thehood">2. Quick overview: How does SHAP work under the hood?</h2>
<p>If you have a bit of time, feel free to read the original paper that describes the different approaches for model explainability and goes through the advantages of SHAP.</p>
<p>But let&#x27;s try to explain in short what SHAP is doing and the concepts behind without getting too deep into the mathematical equations.</p>
<p>Explainable Machine Learning (aka eXplainable AI or XAI) aims at understanding why the output of a machine learning model is such. To do so, you could theoretically take the definition of your model, for example a tree based model like Random Forest, and then see why your output is such. But this is not so straightforward, and of course, it gets even more complex for Deep Learning models…</p>
<p>Instead of going through the winding path of understanding what happens inside your model (forward and backward propagation for deep learning models, which splits are the most used in your RF algo etc). But once you have your trained model, could you not instead use it to see how it reacts when you change a feature?</p>
<p>This is the core concept behind popular XAI algorithm (SHAP, LIME etc): use your existing model, approximate it using an explainable model and you now have an explainable model. The complexity is now on how to approximate a ML model around a given prediction, and then around most predictions.</p>
<p>If you are interested in this and want to learn more, let me know and I&#x27;ll write a follow up article on the mathematical concepts behind SHAP, how it is related to the classic Shapley values, how you can compute SHAP values and how we are able to approximate it for specific use cases, which makes the computation easier.</p>
<hr/>
<p>Woohoo! You now know the basics on how SHAP works and how you can start using it right away in your machine learning projects!</p>
<hr/>
<p>I hope you liked this article! Let me know if you have any questions or suggestions. Also feel free to contact me on LinkedIn, GitHub or Twitter, or checkout some other tutorials I wrote on DS/ML best practices. Happy learning!</p>
<p>Sources:</p>
<ul>
<li><a href="https://shap.readthedocs.io/en/latest/index.html">official documentation</a></li>
<li><a href="https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf">original paper</a></li>
</ul>
<h2 id="about-me">About me</h2>
<p>Hey! 👋 I&#x27;m Armand Sauzay (<a href="https://twitter.com/armandsauzay">armandsauzay</a>). You can find, follow or contact me on:</p>
<ul>
<li><a href="https://github.com/armand-sauzay">Github</a></li>
<li><a href="https://twitter.com/armandsauzay">Twitter</a></li>
<li><a href="https://www.linkedin.com/in/armand-sauzay-80a70b160/">LinkedIn</a></li>
<li><a href="https://medium.com/@armand-sauzay">Medium</a></li>
<li><a href="https://dev.to/armandsauzay">Dev.to</a></li>
</ul></article></main></div></main><footer class="w-full flex justify-center items-center gap-4 p-6 text-sm text-gray-500 mt-auto"><div class="flex gap-8 items-center "><a class="text-gray-500 hover:text-[#24512B] transition-transform transform hover:scale-110 " target="_blank" rel="noopener noreferrer" href="https://github.com/armand-sauzay"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-4 w-4" style="width:16px;height:16px"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg><span class="sr-only">GitHub</span></a><a class="text-gray-500 hover:text-[#24512B] transition-transform transform hover:scale-110 " target="_blank" rel="noopener noreferrer" href="https://linkedin.com/in/armandsauzay"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-linkedin h-4 w-4" style="width:16px;height:16px"><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect width="4" height="12" x="2" y="9"></rect><circle cx="4" cy="4" r="2"></circle></svg><span class="sr-only">LinkedIn</span></a><a class="text-gray-500 hover:text-[#24512B] transition-transform transform hover:scale-110 " href="mailto:sauzayarmand@gmail.com"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail h-4 w-4" style="width:16px;height:16px"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg><span class="sr-only">Email</span></a></div><span class="text-gray-400">© armand sauzay</span></footer><script src="/_next/static/chunks/webpack-87b4446f5aacfc58.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[48173,[\"173\",\"static/chunks/173-24113e259ce525da.js\",\"292\",\"static/chunks/app/articles/page-9a53c5301fbc680c.js\"],\"\"]\n3:I[15244,[],\"\"]\n4:I[43866,[],\"\"]\n6:I[86213,[],\"OutletBoundary\"]\n8:I[86213,[],\"MetadataBoundary\"]\na:I[86213,[],\"ViewportBoundary\"]\nc:I[34835,[],\"\"]\n:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/27c4eb1be0a8ef66.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"PQfJs3TWpIcT2jSkPpTci\",\"p\":\"\",\"c\":[\"\",\"articles\",\"shap-values-machine-learning-interpretability\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"articles\",{\"children\":[[\"slug\",\"shap-values-machine-learning-interpretability\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/27c4eb1be0a8ef66.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__className_d65c78 min-h-screen flex flex-col\",\"children\":[[\"$\",\"div\",null,{\"children\":[[\"$\",\"nav\",null,{\"className\":\"p-6\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto flex justify-between items-center\",\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/\",\"className\":\"text-[#005530] font-semibold text-xl\",\"children\":\"armandsauzay\"}],[\"$\",\"div\",null,{\"className\":\"flex gap-6\",\"children\":[[\"$\",\"$L2\",null,{\"href\":\"/articles\",\"className\":\"text-gray-600 hover:text-[#24512B] transition-colors flex items-center gap-2 cursor-pointer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-book-open h-5 w-5\",\"children\":[[\"$\",\"path\",\"1akyts\",{\"d\":\"M12 7v14\"}],[\"$\",\"path\",\"ruj8y\",{\"d\":\"M3 18a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h5a4 4 0 0 1 4 4 4 4 0 0 1 4-4h5a1 1 0 0 1 1 1v13a1 1 0 0 1-1 1h-6a3 3 0 0 0-3 3 3 3 0 0 0-3-3z\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"children\":\"Articles\"}]]}],[\"$\",\"$L2\",null,{\"href\":\"/projects\",\"className\":\"text-gray-600 hover:text-[#24512B] transition-colors flex items-center gap-2 cursor-pointer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-code-xml h-5 w-5\",\"children\":[[\"$\",\"path\",\"1inbqp\",{\"d\":\"m18 16 4-4-4-4\"}],[\"$\",\"path\",\"15zrgr\",{\"d\":\"m6 8-4 4 4 4\"}],[\"$\",\"path\",\"e7oirm\",{\"d\":\"m14.5 4-5 16\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"children\":\"Projects\"}]]}],[\"$\",\"$L2\",null,{\"href\":\"/creative-lab\",\"className\":\"text-gray-600 hover:text-[#24512B] transition-colors flex items-center gap-2 cursor-pointer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-brain h-5 w-5\",\"children\":[[\"$\",\"path\",\"l5xja\",{\"d\":\"M12 5a3 3 0 1 0-5.997.125 4 4 0 0 0-2.526 5.77 4 4 0 0 0 .556 6.588A4 4 0 1 0 12 18Z\"}],[\"$\",\"path\",\"ep3f8r\",{\"d\":\"M12 5a3 3 0 1 1 5.997.125 4 4 0 0 1 2.526 5.77 4 4 0 0 1-.556 6.588A4 4 0 1 1 12 18Z\"}],[\"$\",\"path\",\"1p4c4q\",{\"d\":\"M15 13a4.5 4.5 0 0 1-3-4 4.5 4.5 0 0 1-3 4\"}],[\"$\",\"path\",\"tmeiqw\",{\"d\":\"M17.599 6.5a3 3 0 0 0 .399-1.375\"}],[\"$\",\"path\",\"105sqy\",{\"d\":\"M6.003 5.125A3 3 0 0 0 6.401 6.5\"}],[\"$\",\"path\",\"ql3yin\",{\"d\":\"M3.477 10.896a4 4 0 0 1 .585-.396\"}],[\"$\",\"path\",\"1qfode\",{\"d\":\"M19.938 10.5a4 4 0 0 1 .585.396\"}],[\"$\",\"path\",\"2e4loj\",{\"d\":\"M6 18a4 4 0 0 1-1.967-.516\"}],[\"$\",\"path\",\"159ez6\",{\"d\":\"M19.967 17.484A4 4 0 0 1 18 18\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"children\":\"Creative Lab\"}]]}]]}]]}]}],[\"$\",\"div\",null,{\"className\":\"max-w-4xl mx-auto border-b border-gray-200\"}]]}],[\"$\",\"main\",null,{\"className\":\"flex-1 flex flex-col items-center justify-center\",\"children\":[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}],[\"$\",\"footer\",null,{\"className\":\"w-full flex justify-center items-center gap-4 p-6 text-sm text-gray-500 mt-auto\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex gap-8 items-center \",\"children\":[[\"$\",\"$L2\",null,{\"href\":\"https://github.com/armand-sauzay\",\"className\":\"text-gray-500 hover:text-[#24512B] transition-transform transform hover:scale-110 \",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-4 w-4\",\"style\":{\"width\":16,\"height\":16},\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"GitHub\"}]]}],[\"$\",\"$L2\",null,{\"href\":\"https://linkedin.com/in/armandsauzay\",\"className\":\"text-gray-500 hover:text-[#24512B] transition-transform transform hover:scale-110 \",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-linkedin h-4 w-4\",\"style\":{\"width\":16,\"height\":16},\"children\":[[\"$\",\"path\",\"c2jq9f\",{\"d\":\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"}],[\"$\",\"rect\",\"mk3on5\",{\"width\":\"4\",\"height\":\"12\",\"x\":\"2\",\"y\":\"9\"}],[\"$\",\"circle\",\"bt5ra8\",{\"cx\":\"4\",\"cy\":\"4\",\"r\":\"2\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"LinkedIn\"}]]}],[\"$\",\"$L2\",null,{\"href\":\"mailto:sauzayarmand@gmail.com\",\"className\":\"text-gray-500 hover:text-[#24512B] transition-transform transform hover:scale-110 \",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-mail h-4 w-4\",\"style\":{\"width\":16,\"height\":16},\"children\":[[\"$\",\"rect\",\"18n3k1\",{\"width\":\"20\",\"height\":\"16\",\"x\":\"2\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"1ocrg3\",{\"d\":\"m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7\"}],\"$undefined\"]}],[\"$\",\"span\",null,{\"className\":\"sr-only\",\"children\":\"Email\"}]]}]]}],[\"$\",\"span\",null,{\"className\":\"text-gray-400\",\"children\":\"© armand sauzay\"}]]}]]}]}]]}],{\"children\":[\"articles\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"articles\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"shap-values-machine-learning-interpretability\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L3\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"articles\",\"children\",\"$0:f:0:1:2:children:2:children:0\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L4\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",null,[\"$\",\"$L6\",null,{\"children\":\"$L7\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"pFQfy9yoAo5fi5LfdHsHa\",{\"children\":[[\"$\",\"$L8\",null,{\"children\":\"$L9\"}],[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$c\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Armand Sauzay\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Personal website of Armand Sauzay\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\"}]]\n"])</script><script>self.__next_f.push([1,"7:null\n"])</script><script>self.__next_f.push([1,"d:I[95958,[\"313\",\"static/chunks/313-6cc61c2fd8ca5084.js\",\"904\",\"static/chunks/app/articles/%5Bslug%5D/page-444914622aa9eeee.js\"],\"default\"]\ne:T21eb,"])</script><script>self.__next_f.push([1,"This article lives on: \n- [Meduim](https://medium.com/@armand-sauzay/shap-values-machine-learning-interpretability-and-feature-selection-made-easy-feb8765f815b)\n- [Dev.to](https://dev.to/armandsauzay/shap-values-machine-learning-interpretability-and-feature-selection-made-easy-396k)\n\n# SHAP values: Machine Learning interpretability and feature selection made easy.\nMachine learning interpretability with hands on code with SHAP.\n\n![Photo by Edu Grande on Unsplash](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9q9Wr6rz5Li6IZcgLD7_Ig.jpeg)\n\u003cp align=\"center\"\u003ePhoto by Edu Grande on Unsplash\u003c/p\u003e\n\nMachine Learning interpretability is becoming increasingly important, especially as ML algorithms are getting more complex.\n\nHow good is your Machine Learning algorithm if it cant be explained? Less performant but explainable models (like linear regression) are sometimes preferred over more performant but black box models (like XGBoost or Neural Networks). This is why research around machine learning explainability (aka eXplainable AI or XAI) has recently been a growing field with amazing projects like SHAP emerging.\n\n\u003e Would you feel confident using a machine learning model if you can't explain what it does?\n\nThis is where SHAP can be of great help: it can explain **any ML model** by giving the influence of each of the features on the target. But this is not all that SHAP can do. \n\nBuild a simple model (sklearn/xgboost/keras) and use SHAP: you now have a feature selection process by looking at features which have the biggest impact on the prediction.\nBut how does SHAP work under the hood? And how can you start using it?\n\nIn this article we'll first get our hands on some python code to see how you can start using SHAP and how it can help you both for explainability and feature selection. \n\nThen, for those of you who want to get into the details of SHAP, we'll go through the theory behind popular XAI tools like SHAP and LIME.\n\n---\n\nAll the code for this tutorial can be found on Kaggle [here](https://www.kaggle.com/code/armandsauzay/shap-interpret-any-ml-model-feature-selection?scriptVersionId=99746743). Feel free to run the notebook yourself or create a copy!\n\n---\n\n## 1. How can you start using SHAP?\n\nHere, we'll go through a simple example with Shap values using the competition Kaggle competition \"House Prices - Advanced Regression Techniques\" to illustrate SHAP. If you are interested or you have never been on Kaggle before, feel free to read more about the data and the competition itself here.\n\nThe process to use shap is quite straightforward: we need to build a model and then use the shap library to explain it.\n![Explanation of how to use SHAP in your Machine Learning Project](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BG6W1B8OW6gUVHPbBXIvIA.png)\n\nunderstand the output of your modelHere, our machine learning model tries to predict the house prices from the data that is given (number of square feet, quality, number of floors etc).\n\nThe usual workflow in terms of code looks like this:\n1. Create an estimator. For instance GradientBoostingRegressor from sklearn.ensemble:\n    ```python\n    estimator = GradientBoostingRegressor(random_state = random_state)\n    ```\n2. Train your estimator:\n    ```python\n    estimator.fit(X_train, y_train)\n    ```\n3. use shap library to calculate the SHAP values. For instance, using the following code:\n    ```python\n    explainer = shap.Explainer(estimator.predict, X100)\n    shap_values = explainer(X100)\n    ```\n4. See what is the impact of each feature using shap.summary_plot:\n    ```python \n    shap.summary_plot(shap_values, max_display=15, show=False)\n    shap.summary_plot(shap_values, max_display=15, show=False)\n    ```\n![Summary plot of feature importance](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9M6mMjsGH_nj0BG_7uJpCg.png)\n\nFor instance, you can see here that OverallQual is the feature that has the most impact on the model output. High values (colored in red on the graph above) of OverallQual can increase a property's price by ~60,000 and low values can decrease a price by ~20,000. Interesting to know if you're in real estate, isn't it?\n\nBut this is not all of what SHAP can do! SHAP can also explain a single prediction.\n\nFor example, using shap.plots.waterfall for a single element in the dataset, you can have the following:\n```python\nshap.plots.waterfall(shap_values[sample_index], max_display=14)\n```\n![Waterfall plot of feature importance for a single example](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGEnQK781FHnjEwexOklbg.png)\n\nFor this specific example, the predicted price was 166k (vs 174k on average). And we can understand why the algorithm predicted such: for instance OverallQual which is high (7) drives the value up but YearBuilt (1925) drives the value down.\n\nYou can now understand the dynamics behind your model, both overall and on specific datapoints. With SHAP, you can more easily see if something is wrong (or does not make sense for your sharpened data science mind) so you can correct it! This is what observability is about.\n\nAnd since SHAP allows you to understand the feature importance of your model, you can also use this for feature selection. For instance\n```python \nshap.summary_plot(shap_values, max_display=15, show=False, plot_type='bar')\n```\n![Barplot of feature importance](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LPp8lnK6n2peGk1wbBb8Og.png)\n\nThen you can see which features do not have a lot of impact on the output of the model. The features usually are noise for your machine learning model and do not bring a lot of predictive value. So removing them from your training set will generally improve the performance, and allow you to tune correctly the hyper parameters without overfitting on noisy data.\n![Worfklow for feature selection in your machine learning project](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zI3DWLj7E71y4jyVHHJx9g.png)\n\u003cp align=\"center\"\u003e How SHAP can be used for feature selection \u003c/p\u003e\n\n\n## 2. Quick overview: How does SHAP work under the hood?\n\nIf you have a bit of time, feel free to read the original paper that describes the different approaches for model explainability and goes through the advantages of SHAP.\n\nBut let's try to explain in short what SHAP is doing and the concepts behind without getting too deep into the mathematical equations.\n\nExplainable Machine Learning (aka eXplainable AI or XAI) aims at understanding why the output of a machine learning model is such. To do so, you could theoretically take the definition of your model, for example a tree based model like Random Forest, and then see why your output is such. But this is not so straightforward, and of course, it gets even more complex for Deep Learning models…\n\nInstead of going through the winding path of understanding what happens inside your model (forward and backward propagation for deep learning models, which splits are the most used in your RF algo etc). But once you have your trained model, could you not instead use it to see how it reacts when you change a feature?\n\nThis is the core concept behind popular XAI algorithm (SHAP, LIME etc): use your existing model, approximate it using an explainable model and you now have an explainable model. The complexity is now on how to approximate a ML model around a given prediction, and then around most predictions.\n\nIf you are interested in this and want to learn more, let me know and I'll write a follow up article on the mathematical concepts behind SHAP, how it is related to the classic Shapley values, how you can compute SHAP values and how we are able to approximate it for specific use cases, which makes the computation easier.\n\n---\n\nWoohoo! You now know the basics on how SHAP works and how you can start using it right away in your machine learning projects!\n\n---\n\nI hope you liked this article! Let me know if you have any questions or suggestions. Also feel free to contact me on LinkedIn, GitHub or Twitter, or checkout some other tutorials I wrote on DS/ML best practices. Happy learning!\n\nSources:\n- [official documentation](https://shap.readthedocs.io/en/latest/index.html)\n- [original paper](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf)\n\n## About me\nHey! 👋 I'm Armand Sauzay ([armandsauzay](https://twitter.com/armandsauzay)). You can find, follow or contact me on: \n\n- [Github](https://github.com/armand-sauzay) \n- [Twitter](https://twitter.com/armandsauzay)\n- [LinkedIn](https://www.linkedin.com/in/armand-sauzay-80a70b160/)\n- [Medium](https://medium.com/@armand-sauzay)\n- [Dev.to](https://dev.to/armandsauzay)"])</script><script>self.__next_f.push([1,"5:[\"$\",\"div\",null,{\"className\":\"min-h-screen flex flex-col\",\"children\":[\"$\",\"main\",null,{\"className\":\"flex-1 max-w-4xl mx-auto px-4 py-16\",\"children\":[\"$\",\"$Ld\",null,{\"markdown\":\"$e\",\"markdownUrl\":\"https://raw.githubusercontent.com/armand-sauzay/blog-posts/main/shap-values-machine-learning-interpretability-and-feature-selection-made-easy/README.md\"}]}]}]\n"])</script></body></html>